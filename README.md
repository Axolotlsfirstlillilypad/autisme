# autisme

Days ago, a guy on one of the freelance data science work forums posted a request. Given public videos of children playing games at home with parents, extract the following features to find the autism severity/confidence scores  (0-9, where 0 is non-autism and 1-9 represents increasing severity) by using computer vision (CV, so basically machine learning with images) techniques or models (pre-trained / ML / DL) so that we can find the individuals with autism/ADHD levels (such as severe autism, mild, medium, lower, or no autism, etc). 

We have to first prepare the main dataset, by labelling footage from videos with a score. This will require we read in the video, with the new Deepface library designed to extract specific facial expressions. Once we have the labels, we save them into  folders for train and test with a 80/20 split (this can vary to your preference, but in my simulations I found this combi to yield the best accuracies). This can be done with os.paths and write function.  This level of involvement in data generation should allow for a clean dataset, but we take care to remove non-sensible labels that are not numbers. 
Then we apply a ML model to make predictions. Because the person wanted a more effective model , I decided to play with CNN potentially generate a closer matching regression model to the true data distribution. We apply several alternating layers of neurons, then use the ubiquitous Maxpooling2D the data to reduce the number of input weights, then finally flatten the equation with Dense to allow the model an easier time making a final classification. Then of course we run 10 epochs for more accuracy, which ends up as 67%. 

I should note here that the image labels are somewhat subjective, so the model should absolutely not be used to make any definitive profiling about a person's autism or lack thereof. Psychology is quite complex, especially with neurodivergence, so a simplified model is unlikely to be able to capture enough of the nuances to be necessarily diagnostic. 
